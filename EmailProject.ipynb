{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__\n",
    "torch.cuda.is_available()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_new_email(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    parts = text.split('\"')  \n",
    "    \n",
    "    subject = parts[1].strip()\n",
    "    body = parts[3].strip()\n",
    "    label = parts[5].strip()\n",
    "    \n",
    "    new_email = {'Subject':subject, 'Body':body, 'Label':label}\n",
    "    return new_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "confirmation_emails = []\n",
    "\n",
    "for i in range(1, 93):\n",
    "    file_path = f\"Data/confirmation/conf{i}.txt\"\n",
    "    new_email = read_new_email(file_path)\n",
    "    confirmation_emails.append(new_email)\n",
    "\n",
    "print(len(confirmation_emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "rejection_emails = []\n",
    "\n",
    "for i in range(1, 105):\n",
    "    file_path = f\"Data/rejections/rejection{i}.txt\"\n",
    "    new_email = read_new_email(file_path)\n",
    "    rejection_emails.append(new_email)\n",
    "\n",
    "print(len(rejection_emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_emails = []\n",
    "\n",
    "\n",
    "for i in range(0, len(confirmation_emails)):\n",
    "    if isinstance(confirmation_emails[i], dict):\n",
    "        all_emails.append(confirmation_emails[i])\n",
    "\n",
    "for i in range(0, len(rejection_emails)):\n",
    "    if isinstance(rejection_emails[i], dict):\n",
    "        all_emails.append(rejection_emails[i])\n",
    "\n",
    "messages = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for i in range(0, len(all_emails)):\n",
    "    text = all_emails[i]['Subject'] + \" \" + all_emails[i]['Body']\n",
    "    label = all_emails[i]['Label']\n",
    "\n",
    "    messages.append(text)\n",
    "    labels.append(label)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages,\n",
    "                                                    labels, \n",
    "                                                    test_size=0.2, \n",
    "                                                    train_size=0.8, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = {\"rejection\": 0,\n",
    "                  \"confirmation\": 1}\n",
    "\n",
    "def tensor_format(arr):\n",
    "    for i in range(0, len(arr)):\n",
    "        if(arr[i] == 'rejection'):\n",
    "            arr[i] = 0\n",
    "        else:\n",
    "            arr[i] = 1\n",
    "\n",
    "\n",
    "tensor_format(y_train)    \n",
    "\n",
    "tensor_format(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1785\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def token_iterator():\n",
    "    for text in X_train:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Build the vocabulary from the iterator\n",
    "vocab = build_vocab_from_iterator(token_iterator(), specials = [\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338\n"
     ]
    }
   ],
   "source": [
    "max_length = max(len(tokenizer(text)) for text in X_train)\n",
    "\n",
    "\n",
    "# def encode_text(text):\n",
    "#     tokens = tokenizer(text)\n",
    "#     return [vocab[token] for token in tokens]\n",
    "\n",
    "def encode_text(text, max_length):\n",
    "    tokens = tokenizer(text)\n",
    "    encoded_tokens = [vocab[token] for token in tokens]\n",
    "    # Pad or truncate sequences to max_length\n",
    "    if len(encoded_tokens) < max_length:\n",
    "        encoded_tokens += [vocab[\"<PAD>\"]] * (max_length - len(encoded_tokens))\n",
    "    else:\n",
    "        encoded_tokens = encoded_tokens[:max_length]\n",
    "    return encoded_tokens\n",
    "\n",
    "y_train_tensors = torch.tensor(y_train, dtype=torch.float)\n",
    "y_test_tensors = torch.tensor(y_test, dtype=torch.float)\n",
    "\n",
    "X_train_tensors = torch.stack([torch.tensor(encode_text(text, max_length), dtype=torch.float) for text in X_train])\n",
    "X_test_tensors = torch.stack([torch.tensor(encode_text(text, max_length), dtype=torch.float) for text in X_test])\n",
    "\n",
    "print(max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmailModel(\n",
       "  (embedding): Embedding(1785, 128)\n",
       "  (fc1): Linear(in_features=43264, out_features=128, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model\n",
    "from torch import nn\n",
    "\n",
    "class EmailModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(1785, embedding_dim=128) #vocab size\n",
    "        self.fc1 = nn.Linear(338*128, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(x.size(0), -1) #flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "model_1 = EmailModel().to(device)\n",
    "model_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function and Optimizer\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy Function\n",
    "\n",
    "def acc_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    accuracy = (correct/len(y_pred)) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss:  0.7026, Acc: 0.00% | Test Loss:  52.5000, Test Acc: 47.50%\n",
      "Epoch: 1 | Loss:  50.7061, Acc: 46.79% | Test Loss:  43.1116, Test Acc: 30.00%\n",
      "Epoch: 2 | Loss:  24.2509, Acc: 49.36% | Test Loss:  46.4719, Test Acc: 52.50%\n",
      "Epoch: 3 | Loss:  43.5513, Acc: 54.49% | Test Loss:  47.5000, Test Acc: 52.50%\n",
      "Epoch: 4 | Loss:  44.3584, Acc: 54.49% | Test Loss:  47.5000, Test Acc: 52.50%\n",
      "Epoch: 5 | Loss:  44.2473, Acc: 55.13% | Test Loss:  47.5000, Test Acc: 52.50%\n",
      "Epoch: 6 | Loss:  44.2308, Acc: 55.77% | Test Loss:  47.5000, Test Acc: 52.50%\n",
      "Epoch: 7 | Loss:  44.2308, Acc: 55.77% | Test Loss:  47.5000, Test Acc: 52.50%\n",
      "Epoch: 8 | Loss:  44.2308, Acc: 55.77% | Test Loss:  47.5000, Test Acc: 52.50%\n",
      "Epoch: 9 | Loss:  44.2308, Acc: 55.77% | Test Loss:  47.5000, Test Acc: 52.50%\n"
     ]
    }
   ],
   "source": [
    "#Training and Testing Loop\n",
    "epochs = 10\n",
    "\n",
    "X_test_tensors = X_test_tensors.long().to(device)\n",
    "X_train_tensors = X_train_tensors.long().to(device)\n",
    "y_train_tensors = y_train_tensors.float().to(device)\n",
    "y_test_tensors = y_test_tensors.float().to(device)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_1.train()\n",
    "\n",
    "    train_preds = model_1(X_train_tensors).squeeze()\n",
    "    train_loss = loss_fn(train_preds, y_train_tensors)\n",
    "    train_acc = acc_fn(y_train_tensors, train_preds)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_preds = model_1(X_test_tensors).squeeze()\n",
    "        test_loss = loss_fn(test_preds, y_test_tensors)\n",
    "        test_acc = acc_fn(y_test_tensors, test_preds)\n",
    "        \n",
    "    print(f\"Epoch: {epoch} | Loss: {train_loss: .4f}, Acc: {train_acc:.2f}% | Test Loss: {test_loss: .4f}, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
